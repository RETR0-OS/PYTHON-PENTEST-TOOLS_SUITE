#!/usr/bin/python3
# Import the libraries we downloaded earlier
# if you try importing without installing them, this step will fail
from bs4 import BeautifulSoup
import requests
import optparse 

def get_arguments():
        parser = optparse.OptionParser() ##Parses options. Reads them and uses them
        parser.add_option("-u", "--url", dest="url", help="URL to scan. eg: https://example.com") ## Adds a help msg for user regarding an option
        (options, arguments) = parser.parse_args()## Allows object to understand what user has entered and handel it. return returns the output of the comman>
        if not options.url:
                parser.error("[-] Run-time error. URL not specified. URL is required. Use --help for more info.")
        else:
        	return options

        
options = get_arguments() ##(options, arguments) helps capture user input.
# requests.get downloads the webpage and stores it as a variable
url = options.url	
html = requests.get(url)

# this parses the webpage into something that beautifulsoup can read over
soup = BeautifulSoup(html.text, "lxml")
# lxml is just the parser for reading the html 
#print(soup)
# this is the line that grabs all the links # stores all the links in the links variable
links = soup.find_all('a')


for link in links:      
    # prints each link    
	if "href" in link.attrs:
		print(link["href"])
